{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "125314d2-3676-40dc-ab18-9bd877960631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2d356-26d5-429a-b5b4-9fbe81d32e53",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "04065671-ef0e-4bc2-a7c5-43e3e777e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTScanDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for label, category in enumerate([\"Normal\", \"Covid\"]):\n",
    "            category_path = os.path.join(root_dir, category)\n",
    "            for img_name in os.listdir(category_path):\n",
    "                self.image_paths.append(os.path.join(category_path, img_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = CTScanDataset(root_dir='/Users/rohanojha/Documents/01_Sem_1_DS 5220 Code/SML_Project/Code_Test/Train/', transform=transform)\n",
    "val_dataset   = CTScanDataset(root_dir='/Users/rohanojha/Documents/01_Sem_1_DS 5220 Code/SML_Project/Code_Test/Val/',   transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b672c4b-6342-41b7-90cb-965bbd902e3d",
   "metadata": {},
   "source": [
    "### Model 1 - 2 Layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1be8f4c-7dd7-4643-b092-3ee27c3bf300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
    "#         self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "        \n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1373cdd0-a6b3-44da-bdae-ca41ca287e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Independent Channel Processing '''\n",
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "#         self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "        \n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Accuracy on Train: 99.87%\n",
    "# # Accuracy on Test: 60.78%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09470255-565d-40f5-a242-5ebea1a4a1d9",
   "metadata": {},
   "source": [
    "### Model 2 - 4 Layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c2ed6d0-2f7c-43e6-ac31-94e159a507c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         # First two convolutional layers (original)\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         # Additional convolutional layers\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         # Pooling and fully connected layers\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(256 * 14 * 14, 128)  # Adjust input size for new layers\n",
    "#         self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "        \n",
    "#         # Activation and dropout\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Pass through convolutional layers with activation and pooling\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = self.pool(self.relu(self.conv3(x)))  # Additional layer\n",
    "#         x = self.pool(self.relu(self.conv4(x)))  # Additional layer\n",
    "        \n",
    "#         # Flatten the tensor for fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8c76fcb-394f-4cad-9451-be848ab39be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Independent Channel Processing '''\n",
    "\n",
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "#         self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "#         self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "        \n",
    "#         # Max pooling layer\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(32 * 14 * 14, 128)  # Adjust this size after pooling\n",
    "#         self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Apply first convolution, ReLU activation, and max pooling\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = self.pool(self.relu(self.conv3(x)))\n",
    "#         x = self.pool(self.relu(self.conv4(x)))\n",
    "        \n",
    "#         # Flatten the tensor to feed into fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        \n",
    "#         # Apply fully connected layers with dropout and ReLU activation\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b569ad9f-4b63-493e-be83-cc7db7bdba08",
   "metadata": {},
   "source": [
    "### Model 3 - 6 Layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "08f464ff-3234-41c9-9062-e13d7c02e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         # First two convolutional layers (original)\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         # Additional convolutional layers\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv6 = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(1024 * 3 * 3, 512)  # Adjust input size for added layers\n",
    "#         self.fc2 = nn.Linear(512, 128)\n",
    "#         self.fc3 = nn.Linear(128, 2)  # Binary classification\n",
    "        \n",
    "#         # Activation and dropout\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Pass through convolutional layers with activation and pooling\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = self.pool(self.relu(self.conv3(x)))\n",
    "#         x = self.pool(self.relu(self.conv4(x)))\n",
    "#         x = self.pool(self.relu(self.conv5(x)))  # Additional layer\n",
    "#         x = self.pool(self.relu(self.conv6(x)))  # Additional layer\n",
    "        \n",
    "#         # Flatten the tensor for fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.dropout(self.relu(self.fc2(x)))\n",
    "#         x = self.fc3(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ddeb2b-7593-4e2a-b79e-264700691f32",
   "metadata": {},
   "source": [
    "### Model 4 - 4 Layer CNN - Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f7c21de8-c881-4146-a827-8a84a451a05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         # First two convolutional layers (original)\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         # Additional convolutional layers\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         # Pooling and fully connected layers\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(256 * 14 * 14, 128)  # Adjust input size for new layers\n",
    "#         self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "        \n",
    "#         # Activation and dropout\n",
    "#         self.activation = nn.LeakyReLU(negative_slope=0.01) \n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Pass through convolutional layers with activation and pooling\n",
    "#         x = self.pool(self.activation(self.conv1(x)))\n",
    "#         x = self.pool(self.activation(self.conv2(x)))\n",
    "#         x = self.pool(self.activation(self.conv3(x)))\n",
    "#         x = self.pool(self.activation(self.conv4(x)))\n",
    "\n",
    "#         # Flatten the tensor for fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.dropout(self.activation(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "eb5eb04b-e5b6-468e-bb25-371c73c1a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         # First two convolutional layers (original)\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         # Additional convolutional layers\n",
    "#         self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         # Pooling and fully connected layers\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(512 * 14 * 14, 128)  # Adjust input size for new layers\n",
    "#         self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "        \n",
    "#         # Activation and dropout\n",
    "#         self.activation = nn.ReLU() \n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Pass through convolutional layers with activation and pooling\n",
    "#         x = self.pool(self.activation(self.conv1(x)))\n",
    "#         x = self.pool(self.activation(self.conv2(x)))\n",
    "#         x = self.pool(self.activation(self.conv3(x)))\n",
    "#         x = self.pool(self.activation(self.conv4(x)))\n",
    "\n",
    "#         # Flatten the tensor for fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.dropout(self.activation(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f7468-42fe-4986-9316-bba12922d1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2944c56a-69f2-4304-9155-ad841c814432",
   "metadata": {},
   "source": [
    "### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "91a1babc-0d92-43f6-ba1a-55769f097820",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomCNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b80b0b-53e7-4299-a5aa-88326eb6defe",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bd45edc3-2059-4aac-85c1-9a62aeab521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6971, Accuracy: 49.13%\n",
      "Epoch [2/10], Loss: 0.6952, Accuracy: 49.35%\n",
      "Epoch [3/10], Loss: 0.6937, Accuracy: 50.22%\n",
      "Epoch [4/10], Loss: 0.6943, Accuracy: 49.35%\n",
      "Epoch [5/10], Loss: 0.6959, Accuracy: 48.70%\n",
      "Epoch [6/10], Loss: 0.6955, Accuracy: 47.39%\n",
      "Epoch [7/10], Loss: 0.6945, Accuracy: 49.02%\n",
      "Epoch [8/10], Loss: 0.6943, Accuracy: 50.33%\n",
      "Epoch [9/10], Loss: 0.6934, Accuracy: 49.24%\n",
      "Epoch [10/10], Loss: 0.6932, Accuracy: 51.74%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5a21b-a377-4a05-933e-812fea678c48",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "77d5587b-7cab-4d8a-9043-08fe44d80c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 52.16%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792379a-4711-4dc2-a768-ed09f2c8784b",
   "metadata": {},
   "source": [
    "### Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a9e462b0-83d1-458b-a223-71dd283f73f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Normal\n"
     ]
    }
   ],
   "source": [
    "# Save the Model\n",
    "torch.save(model.state_dict(), \"covid_ct_model.pth\")\n",
    "\n",
    "# Load the model\n",
    "model = CustomCNN()\n",
    "model.load_state_dict(torch.load(\"covid_ct_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Predict on a single image\n",
    "from PIL import Image\n",
    "\n",
    "# Define the transform used during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the image\n",
    "image_path = \"/Users/rohanojha/Documents/01_Sem_1_DS 5220 Code/SML_Project/Code_Test/single_prediction/normal.png\"  # Replace with the actual path\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Apply transformations\n",
    "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Move the tensor to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_tensor = image_tensor.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    output = model(image_tensor)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "# Map predicted class to label\n",
    "classes = [\"Normal\", \"Covid\"]\n",
    "prediction = classes[predicted_class.item()]\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56653180-1e95-4007-8c84-a94a705f407f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
