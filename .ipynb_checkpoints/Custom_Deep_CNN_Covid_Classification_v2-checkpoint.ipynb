{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "125314d2-3676-40dc-ab18-9bd877960631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2d356-26d5-429a-b5b4-9fbe81d32e53",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "04065671-ef0e-4bc2-a7c5-43e3e777e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTScanDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for label, category in enumerate([\"Normal\", \"Covid\"]):\n",
    "            category_path = os.path.join(root_dir, category)\n",
    "            for img_name in os.listdir(category_path):\n",
    "                self.image_paths.append(os.path.join(category_path, img_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = CTScanDataset(root_dir='/Users/rohanojha/Documents/01_Sem_1_DS 5220 Code/SML_Project/Code_Test/Train/', transform=transform)\n",
    "val_dataset   = CTScanDataset(root_dir='/Users/rohanojha/Documents/01_Sem_1_DS 5220 Code/SML_Project/Code_Test/Val/',   transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09470255-565d-40f5-a242-5ebea1a4a1d9",
   "metadata": {},
   "source": [
    "### Model 2 - 4 Layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c2ed6d0-2f7c-43e6-ac31-94e159a507c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         # First two convolutional layers (original)\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         # Additional convolutional layers\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         # Pooling and fully connected layers\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(256 * 14 * 14, 128)  # Adjust input size for new layers\n",
    "#         self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "        \n",
    "#         # Activation and dropout\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Pass through convolutional layers with activation and pooling\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = self.pool(self.relu(self.conv3(x)))  # Additional layer\n",
    "#         x = self.pool(self.relu(self.conv4(x)))  # Additional layer\n",
    "        \n",
    "#         # Flatten the tensor for fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e8c76fcb-394f-4cad-9451-be848ab39be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Independent Channel Processing '''\n",
    "\n",
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "#         self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "#         self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "        \n",
    "#         # Max pooling layer\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(32 * 14 * 14, 128)  # Adjust this size after pooling\n",
    "#         self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Apply first convolution, ReLU activation, and max pooling\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = self.pool(self.relu(self.conv3(x)))\n",
    "#         x = self.pool(self.relu(self.conv4(x)))\n",
    "        \n",
    "#         # Flatten the tensor to feed into fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        \n",
    "#         # Apply fully connected layers with dropout and ReLU activation\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "000f7468-42fe-4986-9316-bba12922d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Independent Channel Processing '''\n",
    "\n",
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3,  64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, groups=64)\n",
    "#         self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, groups=64)\n",
    "#         self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, groups=64)\n",
    "        \n",
    "#         # Max pooling layer\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(64 * 14 * 14, 128)  # Adjust this size after pooling\n",
    "#         self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Apply first convolution, ReLU activation, and max pooling\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = self.pool(self.relu(self.conv3(x)))\n",
    "#         x = self.pool(self.relu(self.conv4(x)))\n",
    "        \n",
    "#         # Flatten the tensor to feed into fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        \n",
    "#         # Apply fully connected layers with dropout and ReLU activation\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "737ad17c-1bb2-4bac-a14c-7aacf683dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Independent Channel Processing '''\n",
    "\n",
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3,  32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, groups=64)\n",
    "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, groups=128)\n",
    "        \n",
    "#         # Max pooling layer\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(256 * 14 * 14, 128)  # Adjust this size after pooling\n",
    "#         self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Apply first convolution, ReLU activation, and max pooling\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = self.pool(self.relu(self.conv3(x)))\n",
    "#         x = self.pool(self.relu(self.conv4(x)))\n",
    "        \n",
    "#         # Flatten the tensor to feed into fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        \n",
    "#         # Apply fully connected layers with dropout and ReLU activation\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "57fa966b-88b4-4a2f-9e12-9d364b4d8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Independent Channel Processing '''\n",
    "\n",
    "# ''' \n",
    "# Changed the number of neurons in the hidden layers\n",
    "#         1. HL1 : 512\n",
    "#         2. HL2 : 256\n",
    "# Added an additional Hidden Layer \n",
    "# '''\n",
    "\n",
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         # Convolutional layers\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "#         self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "#         self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "        \n",
    "#         # Max pooling layer\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         # Fully connected layers\n",
    "#         self.fc1 = nn.Linear(32 * 14 * 14, 512)  # Adjust this size after pooling\n",
    "#         self.fc2 = nn.Linear(512, 256)  # New additional hidden layer\n",
    "#         self.fc3 = nn.Linear(256, 2)    # Binary classification layer\n",
    "\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Apply convolutional layers with ReLU activation and max pooling\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = self.pool(self.relu(self.conv3(x)))\n",
    "#         x = self.pool(self.relu(self.conv4(x)))\n",
    "        \n",
    "#         # Flatten the tensor to feed into fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        \n",
    "#         # Apply fully connected layers with dropout and ReLU activation\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.dropout(self.relu(self.fc2(x)))  # Additional hidden layer\n",
    "#         x = self.fc3(x)  # Output layer\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "68baae85-b1a0-4899-ab4a-af765d34bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Independent Channel Processing '''\n",
    "\n",
    "'''\n",
    "Changed the number of neurons in the hidden layers\n",
    "        1. HL1 : 512\n",
    "        2. HL2 : 256\n",
    "Max Pool Kernel Size Changed to : 3x3\n",
    "'''\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32)\n",
    "        \n",
    "        # Max pooling layer with 3x3 kernel\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 512)  # Adjusted input size after pooling\n",
    "        self.fc2 = nn.Linear(512, 256)        # Additional hidden layer\n",
    "        self.fc3 = nn.Linear(256, 2)          # Binary classification layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with ReLU activation and max pooling\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = self.pool(self.relu(self.conv4(x)))\n",
    "        \n",
    "        # Flatten the tensor to feed into fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply fully connected layers with dropout and ReLU activation\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))  # Additional hidden layer\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944c56a-69f2-4304-9155-ad841c814432",
   "metadata": {},
   "source": [
    "### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "91a1babc-0d92-43f6-ba1a-55769f097820",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomCNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b80b0b-53e7-4299-a5aa-88326eb6defe",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bd45edc3-2059-4aac-85c1-9a62aeab521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7221, Accuracy: 47.72%\n",
      "Epoch [2/10], Loss: 0.6982, Accuracy: 52.72%\n",
      "Epoch [3/10], Loss: 0.6519, Accuracy: 59.13%\n",
      "Epoch [4/10], Loss: 0.4005, Accuracy: 82.61%\n",
      "Epoch [5/10], Loss: 0.2168, Accuracy: 91.74%\n",
      "Epoch [6/10], Loss: 0.1556, Accuracy: 94.13%\n",
      "Epoch [7/10], Loss: 0.1787, Accuracy: 93.26%\n",
      "Epoch [8/10], Loss: 0.1087, Accuracy: 96.63%\n",
      "Epoch [9/10], Loss: 0.0755, Accuracy: 98.04%\n",
      "Epoch [10/10], Loss: 0.0744, Accuracy: 97.93%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5a21b-a377-4a05-933e-812fea678c48",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "77d5587b-7cab-4d8a-9043-08fe44d80c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 70.26%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792379a-4711-4dc2-a768-ed09f2c8784b",
   "metadata": {},
   "source": [
    "### Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a9e462b0-83d1-458b-a223-71dd283f73f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Normal\n"
     ]
    }
   ],
   "source": [
    "# Save the Model\n",
    "torch.save(model.state_dict(), \"covid_ct_model_ICP_K32_HL_1_2_512Neurons_3MxPl.pth\")\n",
    "\n",
    "# Load the model\n",
    "model = CustomCNN()\n",
    "model.load_state_dict(torch.load(\"covid_ct_model_ICP_K32_HL_1_2_512Neurons_3MxPl.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Predict on a single image\n",
    "from PIL import Image\n",
    "\n",
    "# Define the transform used during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the image\n",
    "# image_path = \"/Users/rohanojha/Documents/01_Sem_1_DS 5220 Code/SML_Project/Code_Test/single_prediction/normal.png\"  # Replace with the actual path\n",
    "# image_path = \"/Users/rohanojha/Documents/01_Sem_1_DS 5220 Code/SML_Project/Code_Test/single_prediction/covid.png\"\n",
    "image_path = \"/Users/rohanojha/Documents/01_Sem_1_DS 5220 Code/SML_Project/Code_Test/single_prediction/Non-Covid (10).png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Apply transformations\n",
    "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Move the tensor to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_tensor = image_tensor.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    output = model(image_tensor)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "# Map predicted class to label\n",
    "classes = [\"Normal\", \"Covid\"]\n",
    "prediction = classes[predicted_class.item()]\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56653180-1e95-4007-8c84-a94a705f407f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
